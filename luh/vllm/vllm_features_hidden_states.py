import numpy as np
import torch
from lm_polygraph.stat_calculators import StatCalculator
from lm_polygraph.model_adapters import WhiteboxModelvLLM


class VLLMHiddenStates(StatCalculator):
    """
    Consumes hidden states generated by VllmHiddenStatesGenerator and returns:
      - vllm_hidden_states: (B, T, H * len(layer_nums))
      - vllm_full_attention_mask: (B, T) with 1 for valid tokens, 0 for padding

    Expected dependency:
      dependencies["vllm_hidden_states_output"] is either:
        - dict with keys: input_ids, hidden_states (list[Tensor]), optional loss_mask
        - list[dict] (one per prompt)
    """

    def __init__(self, layer_nums: list[int]):
        super().__init__()
        self.layer_nums = layer_nums

    @staticmethod
    def meta_info() -> tuple[list[str], list[str]]:
        return (["vllm_hidden_states", "full_attention_mask"], ["vllm_hidden_states_output"])

    def _to_numpy(self, x) -> np.ndarray:
        if isinstance(x, np.ndarray):
            return x
        if torch.is_tensor(x):
            t = x.detach().cpu()
            if t.dtype == torch.bfloat16:
                t = t.float()  # float32
            return t.numpy()
        return np.asarray(x)

    def _normalize_samples(self, hs_out):
        # Accept single dict or list of dicts
        if isinstance(hs_out, dict):
            return [hs_out]
        if isinstance(hs_out, (list, tuple)):
            return list(hs_out)
        raise ValueError(f"Unsupported vllm_hidden_states_output type: {type(hs_out)}")

    def __call__(
            self,
            dependencies: dict[str, np.array],
            texts: list[str],
            model: WhiteboxModelvLLM,
            max_new_tokens: int = 100,
            **kwargs,
    ) -> dict[str, np.ndarray]:

        hs_out = dependencies.get("vllm_hidden_states_output", None)
        if hs_out is None:
            raise ValueError(
                "VLLMHiddenStates requires dependencies['vllm_hidden_states_output'] "
                "from VllmHiddenStatesGenerator (enable output_hidden_states in your wrapper)."
            )

        samples = self._normalize_samples(hs_out)

        per_sample_feats = []
        per_sample_mask = []
        max_len = 0
        out_dim = None

        for s in samples:
            if "hidden_states" not in s:
                raise ValueError("Each sample must contain key 'hidden_states' (list of layer tensors).")

            hs_layers = s["hidden_states"]  # list[Tensor], each [T, H] (typically)
            if not isinstance(hs_layers, (list, tuple)) or len(hs_layers) == 0:
                feats = np.zeros((0, 0), dtype=np.float32)
                mask = np.zeros((0,), dtype=np.int64)
                per_sample_feats.append(feats)
                per_sample_mask.append(mask)
                continue

            # Convert all requested layers to numpy arrays, ensure 2D [T, H]
            hs_layers_np = []
            for layer_tensor in hs_layers:
                a = self._to_numpy(layer_tensor)
                if a.ndim == 3 and a.shape[0] == 1:
                    # sometimes [1, T, H] -> [T, H]
                    a = a[0]
                if a.ndim != 2:
                    raise ValueError(f"Expected layer hidden state to be 2D [T, H], got {a.shape}")
                hs_layers_np.append(a.astype(np.float32, copy=False))

            num_layers, T, H = len(hs_layers_np), hs_layers_np[0].shape[0], hs_layers_np[0].shape[1]
            max_len = max(max_len, T)

            # Validate all layers same shape
            for a in hs_layers_np:
                if a.shape != (T, H):
                    raise ValueError(f"Mismatched layer hidden state shapes: expected {(T, H)}, got {a.shape}")

            # Support negative indexing like HF
            idxs = [(i + num_layers) if i < 0 else i for i in self.layer_nums]
            for i in idxs:
                if i < 0 or i >= num_layers:
                    raise IndexError(f"layer_nums index {i} out of range for {num_layers} provided layers")

            # Concatenate selected layers on feature dimension: [T, H * len(layer_nums)]
            selected = [hs_layers_np[i] for i in idxs]  # each [T, H]
            feats = np.concatenate(selected, axis=-1)  # [T, H*Lsel]
            if out_dim is None:
                out_dim = feats.shape[1]

            # Mask: prefer loss_mask if present, else all ones
            if "loss_mask" in s and s["loss_mask"] is not None:
                m = self._to_numpy(s["loss_mask"]).reshape(-1)
                if m.shape[0] != T:
                    # fall back to "all ones" if mismatch
                    mask = np.ones((T,), dtype=np.int64)
                else:
                    # make binary {0,1}
                    mask = (m != 0).astype(np.int64)
            else:
                mask = np.ones((T,), dtype=np.int64)

            per_sample_feats.append(feats)
            per_sample_mask.append(mask)

        # Handle case where all samples empty
        if out_dim is None:
            out_dim = 0

        B = len(per_sample_feats)
        out = torch.zeros((B, max_len, out_dim), dtype=torch.float32)
        full_attention_mask = torch.zeros((B, max_len), dtype=torch.int64)

        for i in range(B):
            T = per_sample_feats[i].shape[0]
            if T > 0:
                out[i, :T, :] = torch.FloatTensor(per_sample_feats[i])
                full_attention_mask[i, :T] = torch.LongTensor(per_sample_mask[i])

        return {
            "vllm_hidden_states": out[:, :-1, :],
            "full_attention_mask": full_attention_mask,
        }
